{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intent Classification Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq9_ekc_QASY",
        "colab_type": "text"
      },
      "source": [
        "# Intent Classification using Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7TFYlPSRMgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f4c6db3a-bec8-44b0-bc3b-e5f26dd4df25"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or2ggueYLUuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Processing - Main\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Data Processing - Tokenizer and Encoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk import word_tokenize\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Data Processing - Splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "%matplotlib inline\n",
        "\n",
        "# Machine Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, Bidirectional, LSTM, Dropout\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy-lflMILcGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7395bd29-fca0-4bec-8205-f3725810b6a6"
      },
      "source": [
        "# test gpu availability\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvT6mybCMSrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RANDOM_SEED = 13517048\n",
        "np.random.seed(RANDOM_SEED)"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1MYop3XQGcX",
        "colab_type": "text"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkMo3bXBMziv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "a4afe000-c480-49ba-e7ba-82bf419d1bfb"
      },
      "source": [
        "data = pd.read_csv(\"nlu.csv\")\n",
        "data.head(10)"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mau absen 11-14 februari 2020</td>\n",
              "      <td>absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mau absen 11 - 14 februari 2020</td>\n",
              "      <td>absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sick leave besok</td>\n",
              "      <td>absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aku mau absence besok</td>\n",
              "      <td>absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>change working hours besok</td>\n",
              "      <td>absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>change working hour besok</td>\n",
              "      <td>absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>absen besok</td>\n",
              "      <td>absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>change working hours</td>\n",
              "      <td>absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sick leave</td>\n",
              "      <td>absence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>mau absen tanggal 10-11 januari 2012</td>\n",
              "      <td>absence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   text   intent\n",
              "0         mau absen 11-14 februari 2020  absence\n",
              "1       mau absen 11 - 14 februari 2020  absence\n",
              "2                      sick leave besok  absence\n",
              "3                 aku mau absence besok  absence\n",
              "4            change working hours besok  absence\n",
              "5             change working hour besok  absence\n",
              "6                           absen besok  absence\n",
              "7                  change working hours  absence\n",
              "8                            sick leave  absence\n",
              "9  mau absen tanggal 10-11 januari 2012  absence"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b23jlRLNF_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean data:\n",
        "#   - Strip data from special characters\n",
        "#   - Tokenize words\n",
        "#   - Lowercase all word\n",
        "def clean_data(text_data):\n",
        "  words = []\n",
        "  for sentence in text_data:\n",
        "    clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", sentence)\n",
        "    tokenized_words = word_tokenize(clean)\n",
        "\n",
        "    words.append([word.lower() for word in tokenized_words])\n",
        "\n",
        "  return words"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoEFDLchPDrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get max length of every word in words\n",
        "def get_max_length(words):\n",
        "  return len(max(words, key = len))"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6KvNcrcPH6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'\n",
        "\n",
        "def create_tokenizer(words):\n",
        "  token = Tokenizer(filters = filters)\n",
        "  token.fit_on_texts(words)\n",
        "  return token"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m8b5hHwP-3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_train_data(text_data):\n",
        "  # Encoding document\n",
        "  token = create_tokenizer(text_data)\n",
        "  sequences = token.texts_to_sequences(text_data)\n",
        "\n",
        "  max_length = get_max_length(sequences)\n",
        "  return pad_sequences(sequences, maxlen=max_length, padding=\"post\")"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gice1iwHRhfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def onehot_encode(data):\n",
        "  encoder = OneHotEncoder(sparse=False)\n",
        "  return encoder.fit_transform(data)"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl2lvxuDXOL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_data = clean_data(data['text'])"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFj_E_-qXNWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = create_tokenizer(cleaned_data)\n",
        "MAX_LENGTH = get_max_length(cleaned_data)\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D23pwDQgSWla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = create_train_data(cleaned_data)\n",
        "test_data = onehot_encode(data['intent'].values.reshape(-1, 1))\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(train_data, test_data, test_size = 0.2)"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOJUTX77S_WG",
        "colab_type": "text"
      },
      "source": [
        "## Machine Learning Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6FtIWWETo5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(VOCAB_SIZE, 512, input_length=MAX_LENGTH, trainable=False))\n",
        "model.add(Bidirectional(LSTM(512)))\n",
        "model.add(Dense(32, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(y_train.shape[1], activation = \"softmax\"))"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN_VqsMkVfL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "c1c24529-b2de-428a-a56f-28471d2e2dfe"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 23, 512)           362496    \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, 1024)              4198400   \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 32)                32800     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 103)               3399      \n",
            "=================================================================\n",
            "Total params: 4,598,151\n",
            "Trainable params: 4,235,655\n",
            "Non-trainable params: 362,496\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP5ElhpNYq4x",
        "colab_type": "text"
      },
      "source": [
        "### Model Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3lsazb9Yb6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit constants\n",
        "\n",
        "EPOCHS = 250\n",
        "BASIZE = 32"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crepStCMWAI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "11bef956-6522-43ce-8b89-b17d60e94d2b"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs = EPOCHS, batch_size = BASIZE, validation_data = (x_val, y_val))"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "39/39 [==============================] - 3s 70ms/step - loss: 4.6148 - accuracy: 0.0179 - val_loss: 4.5373 - val_accuracy: 0.0261\n",
            "Epoch 2/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 4.5391 - accuracy: 0.0277 - val_loss: 4.4482 - val_accuracy: 0.0456\n",
            "Epoch 3/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 4.4346 - accuracy: 0.0301 - val_loss: 4.2683 - val_accuracy: 0.0651\n",
            "Epoch 4/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 4.3221 - accuracy: 0.0423 - val_loss: 4.1387 - val_accuracy: 0.0651\n",
            "Epoch 5/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 4.2183 - accuracy: 0.0521 - val_loss: 4.0889 - val_accuracy: 0.0651\n",
            "Epoch 6/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 4.1122 - accuracy: 0.0513 - val_loss: 3.9777 - val_accuracy: 0.0684\n",
            "Epoch 7/250\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 4.0296 - accuracy: 0.0643 - val_loss: 3.9077 - val_accuracy: 0.0814\n",
            "Epoch 8/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 3.9815 - accuracy: 0.0700 - val_loss: 3.8246 - val_accuracy: 0.0912\n",
            "Epoch 9/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 3.9002 - accuracy: 0.0831 - val_loss: 3.7657 - val_accuracy: 0.0814\n",
            "Epoch 10/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 3.8014 - accuracy: 0.0863 - val_loss: 3.6422 - val_accuracy: 0.1140\n",
            "Epoch 11/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 3.7486 - accuracy: 0.0985 - val_loss: 3.5214 - val_accuracy: 0.1336\n",
            "Epoch 12/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 3.6874 - accuracy: 0.1059 - val_loss: 3.4349 - val_accuracy: 0.1694\n",
            "Epoch 13/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 3.5531 - accuracy: 0.1197 - val_loss: 3.3691 - val_accuracy: 0.1857\n",
            "Epoch 14/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 3.4638 - accuracy: 0.1287 - val_loss: 3.1856 - val_accuracy: 0.2476\n",
            "Epoch 15/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 3.3847 - accuracy: 0.1572 - val_loss: 3.1240 - val_accuracy: 0.2671\n",
            "Epoch 16/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 3.2787 - accuracy: 0.1702 - val_loss: 3.0498 - val_accuracy: 0.3094\n",
            "Epoch 17/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 3.2201 - accuracy: 0.1881 - val_loss: 2.9744 - val_accuracy: 0.3420\n",
            "Epoch 18/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 3.1251 - accuracy: 0.1881 - val_loss: 2.8134 - val_accuracy: 0.3713\n",
            "Epoch 19/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 3.0345 - accuracy: 0.1971 - val_loss: 2.7910 - val_accuracy: 0.3388\n",
            "Epoch 20/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.9827 - accuracy: 0.2207 - val_loss: 2.6856 - val_accuracy: 0.3811\n",
            "Epoch 21/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.8876 - accuracy: 0.2353 - val_loss: 2.6016 - val_accuracy: 0.3941\n",
            "Epoch 22/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.8676 - accuracy: 0.2313 - val_loss: 2.5569 - val_accuracy: 0.3811\n",
            "Epoch 23/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.7812 - accuracy: 0.2451 - val_loss: 2.4949 - val_accuracy: 0.3811\n",
            "Epoch 24/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.7859 - accuracy: 0.2728 - val_loss: 2.4832 - val_accuracy: 0.4007\n",
            "Epoch 25/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.6945 - accuracy: 0.2516 - val_loss: 2.3757 - val_accuracy: 0.4397\n",
            "Epoch 26/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.6071 - accuracy: 0.2850 - val_loss: 2.4185 - val_accuracy: 0.4560\n",
            "Epoch 27/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.6325 - accuracy: 0.2752 - val_loss: 2.3416 - val_accuracy: 0.4495\n",
            "Epoch 28/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.5579 - accuracy: 0.2777 - val_loss: 2.3497 - val_accuracy: 0.4560\n",
            "Epoch 29/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.5492 - accuracy: 0.3062 - val_loss: 2.2713 - val_accuracy: 0.4495\n",
            "Epoch 30/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.5018 - accuracy: 0.3013 - val_loss: 2.2446 - val_accuracy: 0.4528\n",
            "Epoch 31/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.4708 - accuracy: 0.3208 - val_loss: 2.2574 - val_accuracy: 0.4300\n",
            "Epoch 32/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.4058 - accuracy: 0.3184 - val_loss: 2.2389 - val_accuracy: 0.4788\n",
            "Epoch 33/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.4050 - accuracy: 0.3290 - val_loss: 2.1546 - val_accuracy: 0.4625\n",
            "Epoch 34/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.3782 - accuracy: 0.3322 - val_loss: 2.2140 - val_accuracy: 0.4691\n",
            "Epoch 35/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.3867 - accuracy: 0.3103 - val_loss: 2.2262 - val_accuracy: 0.4560\n",
            "Epoch 36/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.3264 - accuracy: 0.3404 - val_loss: 2.1741 - val_accuracy: 0.4821\n",
            "Epoch 37/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.2322 - accuracy: 0.3518 - val_loss: 2.1347 - val_accuracy: 0.4788\n",
            "Epoch 38/250\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 2.2148 - accuracy: 0.3583 - val_loss: 2.0825 - val_accuracy: 0.4919\n",
            "Epoch 39/250\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 2.1720 - accuracy: 0.3640 - val_loss: 2.1523 - val_accuracy: 0.4951\n",
            "Epoch 40/250\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 2.2414 - accuracy: 0.3355 - val_loss: 2.0073 - val_accuracy: 0.5179\n",
            "Epoch 41/250\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 2.2115 - accuracy: 0.3738 - val_loss: 2.0088 - val_accuracy: 0.4756\n",
            "Epoch 42/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.1656 - accuracy: 0.3762 - val_loss: 2.0169 - val_accuracy: 0.5147\n",
            "Epoch 43/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.1260 - accuracy: 0.3673 - val_loss: 2.0162 - val_accuracy: 0.4788\n",
            "Epoch 44/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.1638 - accuracy: 0.3534 - val_loss: 2.1326 - val_accuracy: 0.4821\n",
            "Epoch 45/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.1002 - accuracy: 0.3868 - val_loss: 2.0576 - val_accuracy: 0.4919\n",
            "Epoch 46/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.1343 - accuracy: 0.3779 - val_loss: 2.0234 - val_accuracy: 0.5309\n",
            "Epoch 47/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.0740 - accuracy: 0.3827 - val_loss: 2.0006 - val_accuracy: 0.5016\n",
            "Epoch 48/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.0918 - accuracy: 0.3713 - val_loss: 1.9855 - val_accuracy: 0.5179\n",
            "Epoch 49/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.0479 - accuracy: 0.4007 - val_loss: 1.9681 - val_accuracy: 0.5147\n",
            "Epoch 50/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.0202 - accuracy: 0.3933 - val_loss: 2.0183 - val_accuracy: 0.5081\n",
            "Epoch 51/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.9770 - accuracy: 0.3966 - val_loss: 1.9436 - val_accuracy: 0.5114\n",
            "Epoch 52/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.0100 - accuracy: 0.4007 - val_loss: 1.9590 - val_accuracy: 0.4984\n",
            "Epoch 53/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.0331 - accuracy: 0.3795 - val_loss: 1.9915 - val_accuracy: 0.4853\n",
            "Epoch 54/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 2.0311 - accuracy: 0.3941 - val_loss: 1.9961 - val_accuracy: 0.5179\n",
            "Epoch 55/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.9378 - accuracy: 0.4088 - val_loss: 1.9294 - val_accuracy: 0.5277\n",
            "Epoch 56/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.9711 - accuracy: 0.3974 - val_loss: 1.9547 - val_accuracy: 0.5016\n",
            "Epoch 57/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.9604 - accuracy: 0.4283 - val_loss: 1.9036 - val_accuracy: 0.5309\n",
            "Epoch 58/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.9417 - accuracy: 0.4088 - val_loss: 2.0187 - val_accuracy: 0.5147\n",
            "Epoch 59/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.9117 - accuracy: 0.4324 - val_loss: 1.9815 - val_accuracy: 0.4951\n",
            "Epoch 60/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.9338 - accuracy: 0.4169 - val_loss: 2.0662 - val_accuracy: 0.5049\n",
            "Epoch 61/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.8504 - accuracy: 0.4161 - val_loss: 2.0113 - val_accuracy: 0.5147\n",
            "Epoch 62/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.8421 - accuracy: 0.4381 - val_loss: 2.0174 - val_accuracy: 0.5309\n",
            "Epoch 63/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.8360 - accuracy: 0.4316 - val_loss: 1.9286 - val_accuracy: 0.5212\n",
            "Epoch 64/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.8516 - accuracy: 0.4357 - val_loss: 1.8742 - val_accuracy: 0.5081\n",
            "Epoch 65/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.8441 - accuracy: 0.4267 - val_loss: 1.9060 - val_accuracy: 0.5309\n",
            "Epoch 66/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.8111 - accuracy: 0.4511 - val_loss: 1.8911 - val_accuracy: 0.5016\n",
            "Epoch 67/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.8428 - accuracy: 0.4381 - val_loss: 1.9774 - val_accuracy: 0.5212\n",
            "Epoch 68/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.7843 - accuracy: 0.4593 - val_loss: 2.0021 - val_accuracy: 0.5049\n",
            "Epoch 69/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.8632 - accuracy: 0.4194 - val_loss: 1.9152 - val_accuracy: 0.5472\n",
            "Epoch 70/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.7776 - accuracy: 0.4446 - val_loss: 1.9091 - val_accuracy: 0.5309\n",
            "Epoch 71/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.7872 - accuracy: 0.4536 - val_loss: 1.9748 - val_accuracy: 0.5081\n",
            "Epoch 72/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.7491 - accuracy: 0.4609 - val_loss: 1.9562 - val_accuracy: 0.5212\n",
            "Epoch 73/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.7983 - accuracy: 0.4438 - val_loss: 1.9046 - val_accuracy: 0.5147\n",
            "Epoch 74/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.7912 - accuracy: 0.4463 - val_loss: 1.9482 - val_accuracy: 0.5472\n",
            "Epoch 75/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.7376 - accuracy: 0.4682 - val_loss: 1.9069 - val_accuracy: 0.5603\n",
            "Epoch 76/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6764 - accuracy: 0.4731 - val_loss: 2.0587 - val_accuracy: 0.5472\n",
            "Epoch 77/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6690 - accuracy: 0.4699 - val_loss: 2.0689 - val_accuracy: 0.5537\n",
            "Epoch 78/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6962 - accuracy: 0.4764 - val_loss: 2.0423 - val_accuracy: 0.5342\n",
            "Epoch 79/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.7275 - accuracy: 0.4764 - val_loss: 2.0047 - val_accuracy: 0.5407\n",
            "Epoch 80/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6732 - accuracy: 0.4731 - val_loss: 2.1090 - val_accuracy: 0.5277\n",
            "Epoch 81/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6952 - accuracy: 0.4601 - val_loss: 2.0216 - val_accuracy: 0.5505\n",
            "Epoch 82/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6804 - accuracy: 0.4739 - val_loss: 1.9352 - val_accuracy: 0.5603\n",
            "Epoch 83/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6931 - accuracy: 0.4780 - val_loss: 1.9506 - val_accuracy: 0.5375\n",
            "Epoch 84/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6327 - accuracy: 0.4870 - val_loss: 2.0135 - val_accuracy: 0.5472\n",
            "Epoch 85/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6758 - accuracy: 0.4748 - val_loss: 1.9314 - val_accuracy: 0.5505\n",
            "Epoch 86/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6375 - accuracy: 0.4886 - val_loss: 2.1245 - val_accuracy: 0.5798\n",
            "Epoch 87/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6692 - accuracy: 0.4919 - val_loss: 2.0498 - val_accuracy: 0.5537\n",
            "Epoch 88/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6331 - accuracy: 0.4870 - val_loss: 2.0228 - val_accuracy: 0.5440\n",
            "Epoch 89/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6872 - accuracy: 0.4658 - val_loss: 2.1754 - val_accuracy: 0.5472\n",
            "Epoch 90/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6469 - accuracy: 0.4943 - val_loss: 2.1294 - val_accuracy: 0.5798\n",
            "Epoch 91/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6217 - accuracy: 0.4788 - val_loss: 1.9674 - val_accuracy: 0.5635\n",
            "Epoch 92/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5829 - accuracy: 0.4976 - val_loss: 2.0121 - val_accuracy: 0.5700\n",
            "Epoch 93/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6350 - accuracy: 0.4886 - val_loss: 1.8837 - val_accuracy: 0.5798\n",
            "Epoch 94/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6096 - accuracy: 0.4992 - val_loss: 1.9975 - val_accuracy: 0.5765\n",
            "Epoch 95/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5901 - accuracy: 0.4992 - val_loss: 1.9640 - val_accuracy: 0.5603\n",
            "Epoch 96/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5545 - accuracy: 0.5179 - val_loss: 2.0025 - val_accuracy: 0.5603\n",
            "Epoch 97/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5639 - accuracy: 0.5155 - val_loss: 2.0717 - val_accuracy: 0.5798\n",
            "Epoch 98/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5841 - accuracy: 0.4927 - val_loss: 2.0689 - val_accuracy: 0.5733\n",
            "Epoch 99/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5894 - accuracy: 0.5000 - val_loss: 2.1169 - val_accuracy: 0.5765\n",
            "Epoch 100/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5611 - accuracy: 0.5041 - val_loss: 2.0591 - val_accuracy: 0.5668\n",
            "Epoch 101/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5836 - accuracy: 0.4927 - val_loss: 2.0391 - val_accuracy: 0.5863\n",
            "Epoch 102/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5789 - accuracy: 0.5033 - val_loss: 2.1462 - val_accuracy: 0.5798\n",
            "Epoch 103/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5301 - accuracy: 0.5106 - val_loss: 2.1838 - val_accuracy: 0.5831\n",
            "Epoch 104/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5325 - accuracy: 0.5293 - val_loss: 2.1540 - val_accuracy: 0.5798\n",
            "Epoch 105/250\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 1.4788 - accuracy: 0.5179 - val_loss: 2.1423 - val_accuracy: 0.5798\n",
            "Epoch 106/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5584 - accuracy: 0.5008 - val_loss: 2.1234 - val_accuracy: 0.5733\n",
            "Epoch 107/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5045 - accuracy: 0.5090 - val_loss: 2.1027 - val_accuracy: 0.5863\n",
            "Epoch 108/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5717 - accuracy: 0.5065 - val_loss: 2.1043 - val_accuracy: 0.5798\n",
            "Epoch 109/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.6232 - accuracy: 0.4935 - val_loss: 1.9260 - val_accuracy: 0.5603\n",
            "Epoch 110/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5623 - accuracy: 0.4992 - val_loss: 1.9718 - val_accuracy: 0.5765\n",
            "Epoch 111/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4734 - accuracy: 0.5383 - val_loss: 2.1207 - val_accuracy: 0.5993\n",
            "Epoch 112/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5060 - accuracy: 0.5277 - val_loss: 2.0370 - val_accuracy: 0.5863\n",
            "Epoch 113/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4962 - accuracy: 0.5358 - val_loss: 2.1217 - val_accuracy: 0.5896\n",
            "Epoch 114/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.5439 - accuracy: 0.5065 - val_loss: 2.1967 - val_accuracy: 0.5570\n",
            "Epoch 115/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4739 - accuracy: 0.5147 - val_loss: 2.1190 - val_accuracy: 0.6254\n",
            "Epoch 116/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4452 - accuracy: 0.5391 - val_loss: 2.1285 - val_accuracy: 0.6059\n",
            "Epoch 117/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4603 - accuracy: 0.5277 - val_loss: 2.3049 - val_accuracy: 0.5993\n",
            "Epoch 118/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4694 - accuracy: 0.5350 - val_loss: 2.0921 - val_accuracy: 0.6059\n",
            "Epoch 119/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4828 - accuracy: 0.5285 - val_loss: 2.0986 - val_accuracy: 0.6026\n",
            "Epoch 120/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4425 - accuracy: 0.5342 - val_loss: 2.1686 - val_accuracy: 0.5928\n",
            "Epoch 121/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3969 - accuracy: 0.5423 - val_loss: 2.1895 - val_accuracy: 0.5928\n",
            "Epoch 122/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3975 - accuracy: 0.5464 - val_loss: 2.2370 - val_accuracy: 0.6059\n",
            "Epoch 123/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4121 - accuracy: 0.5497 - val_loss: 2.3984 - val_accuracy: 0.5928\n",
            "Epoch 124/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4404 - accuracy: 0.5342 - val_loss: 2.1782 - val_accuracy: 0.5863\n",
            "Epoch 125/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4103 - accuracy: 0.5423 - val_loss: 2.2373 - val_accuracy: 0.6026\n",
            "Epoch 126/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4387 - accuracy: 0.5236 - val_loss: 2.2901 - val_accuracy: 0.5896\n",
            "Epoch 127/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3953 - accuracy: 0.5505 - val_loss: 2.2259 - val_accuracy: 0.6124\n",
            "Epoch 128/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3512 - accuracy: 0.5635 - val_loss: 2.2620 - val_accuracy: 0.6026\n",
            "Epoch 129/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3389 - accuracy: 0.5529 - val_loss: 2.2615 - val_accuracy: 0.6059\n",
            "Epoch 130/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4508 - accuracy: 0.5358 - val_loss: 2.4355 - val_accuracy: 0.5896\n",
            "Epoch 131/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4036 - accuracy: 0.5578 - val_loss: 2.3564 - val_accuracy: 0.5863\n",
            "Epoch 132/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3771 - accuracy: 0.5423 - val_loss: 2.3111 - val_accuracy: 0.6124\n",
            "Epoch 133/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3229 - accuracy: 0.5708 - val_loss: 2.4852 - val_accuracy: 0.6091\n",
            "Epoch 134/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3792 - accuracy: 0.5546 - val_loss: 2.4733 - val_accuracy: 0.5896\n",
            "Epoch 135/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4388 - accuracy: 0.5212 - val_loss: 2.2494 - val_accuracy: 0.5863\n",
            "Epoch 136/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3755 - accuracy: 0.5570 - val_loss: 2.2937 - val_accuracy: 0.5863\n",
            "Epoch 137/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3794 - accuracy: 0.5432 - val_loss: 2.1208 - val_accuracy: 0.5961\n",
            "Epoch 138/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4288 - accuracy: 0.5309 - val_loss: 2.3531 - val_accuracy: 0.6221\n",
            "Epoch 139/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3871 - accuracy: 0.5586 - val_loss: 2.2893 - val_accuracy: 0.6091\n",
            "Epoch 140/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3245 - accuracy: 0.5668 - val_loss: 2.3567 - val_accuracy: 0.5863\n",
            "Epoch 141/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4100 - accuracy: 0.5578 - val_loss: 2.2622 - val_accuracy: 0.6091\n",
            "Epoch 142/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3162 - accuracy: 0.5700 - val_loss: 2.4625 - val_accuracy: 0.5961\n",
            "Epoch 143/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3435 - accuracy: 0.5749 - val_loss: 2.4413 - val_accuracy: 0.5928\n",
            "Epoch 144/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3179 - accuracy: 0.5643 - val_loss: 2.5305 - val_accuracy: 0.5961\n",
            "Epoch 145/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3192 - accuracy: 0.5684 - val_loss: 2.4705 - val_accuracy: 0.5928\n",
            "Epoch 146/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3447 - accuracy: 0.5635 - val_loss: 2.5575 - val_accuracy: 0.5928\n",
            "Epoch 147/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3270 - accuracy: 0.5586 - val_loss: 2.3277 - val_accuracy: 0.6156\n",
            "Epoch 148/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3292 - accuracy: 0.5586 - val_loss: 2.5170 - val_accuracy: 0.6254\n",
            "Epoch 149/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3228 - accuracy: 0.5708 - val_loss: 2.5642 - val_accuracy: 0.6091\n",
            "Epoch 150/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3301 - accuracy: 0.5586 - val_loss: 2.7201 - val_accuracy: 0.6319\n",
            "Epoch 151/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3265 - accuracy: 0.5765 - val_loss: 2.3898 - val_accuracy: 0.6189\n",
            "Epoch 152/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3398 - accuracy: 0.5749 - val_loss: 2.4500 - val_accuracy: 0.6091\n",
            "Epoch 153/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3282 - accuracy: 0.5676 - val_loss: 2.4557 - val_accuracy: 0.6091\n",
            "Epoch 154/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3115 - accuracy: 0.5708 - val_loss: 2.4850 - val_accuracy: 0.6254\n",
            "Epoch 155/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3388 - accuracy: 0.5611 - val_loss: 2.6043 - val_accuracy: 0.6124\n",
            "Epoch 156/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3839 - accuracy: 0.5611 - val_loss: 2.4310 - val_accuracy: 0.6156\n",
            "Epoch 157/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.4462 - accuracy: 0.5554 - val_loss: 2.8924 - val_accuracy: 0.6091\n",
            "Epoch 158/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3213 - accuracy: 0.5757 - val_loss: 2.5053 - val_accuracy: 0.6287\n",
            "Epoch 159/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3264 - accuracy: 0.5863 - val_loss: 2.3969 - val_accuracy: 0.6417\n",
            "Epoch 160/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2904 - accuracy: 0.5814 - val_loss: 2.6777 - val_accuracy: 0.5863\n",
            "Epoch 161/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2905 - accuracy: 0.5831 - val_loss: 2.3221 - val_accuracy: 0.6059\n",
            "Epoch 162/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3122 - accuracy: 0.5863 - val_loss: 2.3710 - val_accuracy: 0.5863\n",
            "Epoch 163/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3136 - accuracy: 0.5822 - val_loss: 2.3701 - val_accuracy: 0.5928\n",
            "Epoch 164/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.3226 - accuracy: 0.5627 - val_loss: 2.2869 - val_accuracy: 0.6059\n",
            "Epoch 165/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2612 - accuracy: 0.5855 - val_loss: 2.5226 - val_accuracy: 0.6059\n",
            "Epoch 166/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2664 - accuracy: 0.5831 - val_loss: 2.5706 - val_accuracy: 0.5993\n",
            "Epoch 167/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2531 - accuracy: 0.5822 - val_loss: 2.7948 - val_accuracy: 0.6156\n",
            "Epoch 168/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2608 - accuracy: 0.5928 - val_loss: 2.6703 - val_accuracy: 0.5993\n",
            "Epoch 169/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2647 - accuracy: 0.5904 - val_loss: 2.6639 - val_accuracy: 0.6026\n",
            "Epoch 170/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2648 - accuracy: 0.5879 - val_loss: 2.5652 - val_accuracy: 0.5993\n",
            "Epoch 171/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1942 - accuracy: 0.6067 - val_loss: 2.6686 - val_accuracy: 0.6156\n",
            "Epoch 172/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2264 - accuracy: 0.6034 - val_loss: 2.6218 - val_accuracy: 0.6026\n",
            "Epoch 173/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2693 - accuracy: 0.5920 - val_loss: 2.4296 - val_accuracy: 0.6384\n",
            "Epoch 174/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2629 - accuracy: 0.5822 - val_loss: 2.5778 - val_accuracy: 0.6287\n",
            "Epoch 175/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2207 - accuracy: 0.5985 - val_loss: 2.5679 - val_accuracy: 0.6384\n",
            "Epoch 176/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2639 - accuracy: 0.5879 - val_loss: 2.6526 - val_accuracy: 0.6026\n",
            "Epoch 177/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1820 - accuracy: 0.6181 - val_loss: 2.7243 - val_accuracy: 0.6059\n",
            "Epoch 178/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2311 - accuracy: 0.6026 - val_loss: 2.9032 - val_accuracy: 0.5961\n",
            "Epoch 179/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2524 - accuracy: 0.5863 - val_loss: 2.9000 - val_accuracy: 0.6189\n",
            "Epoch 180/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2394 - accuracy: 0.5806 - val_loss: 2.7633 - val_accuracy: 0.6287\n",
            "Epoch 181/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2023 - accuracy: 0.5912 - val_loss: 2.9682 - val_accuracy: 0.6221\n",
            "Epoch 182/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2590 - accuracy: 0.5806 - val_loss: 2.8051 - val_accuracy: 0.6124\n",
            "Epoch 183/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2731 - accuracy: 0.5953 - val_loss: 2.7236 - val_accuracy: 0.6254\n",
            "Epoch 184/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2353 - accuracy: 0.6018 - val_loss: 2.8106 - val_accuracy: 0.6189\n",
            "Epoch 185/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1869 - accuracy: 0.6002 - val_loss: 2.9431 - val_accuracy: 0.6189\n",
            "Epoch 186/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2346 - accuracy: 0.5774 - val_loss: 2.9270 - val_accuracy: 0.6287\n",
            "Epoch 187/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2057 - accuracy: 0.5879 - val_loss: 2.9700 - val_accuracy: 0.6254\n",
            "Epoch 188/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1573 - accuracy: 0.6246 - val_loss: 2.9720 - val_accuracy: 0.6287\n",
            "Epoch 189/250\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 1.2006 - accuracy: 0.5920 - val_loss: 2.8423 - val_accuracy: 0.6189\n",
            "Epoch 190/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2324 - accuracy: 0.5945 - val_loss: 2.9391 - val_accuracy: 0.6287\n",
            "Epoch 191/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1796 - accuracy: 0.6107 - val_loss: 3.0566 - val_accuracy: 0.6319\n",
            "Epoch 192/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1525 - accuracy: 0.6221 - val_loss: 3.0860 - val_accuracy: 0.6254\n",
            "Epoch 193/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2360 - accuracy: 0.5888 - val_loss: 2.9862 - val_accuracy: 0.6156\n",
            "Epoch 194/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1918 - accuracy: 0.5888 - val_loss: 3.2358 - val_accuracy: 0.6221\n",
            "Epoch 195/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2241 - accuracy: 0.6018 - val_loss: 2.8941 - val_accuracy: 0.6124\n",
            "Epoch 196/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1916 - accuracy: 0.6034 - val_loss: 3.0787 - val_accuracy: 0.6091\n",
            "Epoch 197/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2235 - accuracy: 0.5847 - val_loss: 3.0624 - val_accuracy: 0.6384\n",
            "Epoch 198/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1997 - accuracy: 0.6067 - val_loss: 2.9824 - val_accuracy: 0.6221\n",
            "Epoch 199/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1676 - accuracy: 0.6173 - val_loss: 3.1671 - val_accuracy: 0.6287\n",
            "Epoch 200/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1534 - accuracy: 0.6091 - val_loss: 3.2789 - val_accuracy: 0.6287\n",
            "Epoch 201/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1655 - accuracy: 0.6230 - val_loss: 3.3066 - val_accuracy: 0.5896\n",
            "Epoch 202/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1622 - accuracy: 0.6303 - val_loss: 3.0436 - val_accuracy: 0.6221\n",
            "Epoch 203/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2036 - accuracy: 0.6067 - val_loss: 3.2080 - val_accuracy: 0.6254\n",
            "Epoch 204/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1468 - accuracy: 0.6254 - val_loss: 3.3690 - val_accuracy: 0.6026\n",
            "Epoch 205/250\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 1.1481 - accuracy: 0.6156 - val_loss: 3.0728 - val_accuracy: 0.6124\n",
            "Epoch 206/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1884 - accuracy: 0.6010 - val_loss: 3.3368 - val_accuracy: 0.6156\n",
            "Epoch 207/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1586 - accuracy: 0.6213 - val_loss: 3.1628 - val_accuracy: 0.6319\n",
            "Epoch 208/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1936 - accuracy: 0.6205 - val_loss: 2.9322 - val_accuracy: 0.6156\n",
            "Epoch 209/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1420 - accuracy: 0.6246 - val_loss: 3.1663 - val_accuracy: 0.6221\n",
            "Epoch 210/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1472 - accuracy: 0.6238 - val_loss: 3.3813 - val_accuracy: 0.6156\n",
            "Epoch 211/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1704 - accuracy: 0.6156 - val_loss: 2.9290 - val_accuracy: 0.6059\n",
            "Epoch 212/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2268 - accuracy: 0.6091 - val_loss: 2.6534 - val_accuracy: 0.6254\n",
            "Epoch 213/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1055 - accuracy: 0.6360 - val_loss: 2.8943 - val_accuracy: 0.6287\n",
            "Epoch 214/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1880 - accuracy: 0.6002 - val_loss: 2.7510 - val_accuracy: 0.6384\n",
            "Epoch 215/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1783 - accuracy: 0.6173 - val_loss: 2.9888 - val_accuracy: 0.6287\n",
            "Epoch 216/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2092 - accuracy: 0.6213 - val_loss: 3.0335 - val_accuracy: 0.6352\n",
            "Epoch 217/250\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 1.1959 - accuracy: 0.6189 - val_loss: 3.2414 - val_accuracy: 0.6221\n",
            "Epoch 218/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.2027 - accuracy: 0.6050 - val_loss: 2.8587 - val_accuracy: 0.6124\n",
            "Epoch 219/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1587 - accuracy: 0.6124 - val_loss: 2.8591 - val_accuracy: 0.6189\n",
            "Epoch 220/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1316 - accuracy: 0.6311 - val_loss: 2.9130 - val_accuracy: 0.6189\n",
            "Epoch 221/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.0993 - accuracy: 0.6384 - val_loss: 3.0920 - val_accuracy: 0.6189\n",
            "Epoch 222/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1427 - accuracy: 0.6189 - val_loss: 3.2407 - val_accuracy: 0.6221\n",
            "Epoch 223/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1080 - accuracy: 0.6360 - val_loss: 3.1873 - val_accuracy: 0.6254\n",
            "Epoch 224/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.0828 - accuracy: 0.6376 - val_loss: 2.9270 - val_accuracy: 0.6319\n",
            "Epoch 225/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.0934 - accuracy: 0.6327 - val_loss: 2.8347 - val_accuracy: 0.6221\n",
            "Epoch 226/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.0869 - accuracy: 0.6474 - val_loss: 3.1820 - val_accuracy: 0.6319\n",
            "Epoch 227/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1137 - accuracy: 0.6490 - val_loss: 3.3651 - val_accuracy: 0.6156\n",
            "Epoch 228/250\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 1.1494 - accuracy: 0.6246 - val_loss: 3.2656 - val_accuracy: 0.6254\n",
            "Epoch 229/250\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 1.1148 - accuracy: 0.6319 - val_loss: 3.3639 - val_accuracy: 0.6352\n",
            "Epoch 230/250\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 1.0904 - accuracy: 0.6507 - val_loss: 3.4173 - val_accuracy: 0.6221\n",
            "Epoch 231/250\n",
            "39/39 [==============================] - 1s 35ms/step - loss: 1.1233 - accuracy: 0.6311 - val_loss: 3.1965 - val_accuracy: 0.6156\n",
            "Epoch 232/250\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 1.1287 - accuracy: 0.6164 - val_loss: 3.5799 - val_accuracy: 0.6156\n",
            "Epoch 233/250\n",
            "39/39 [==============================] - 1s 34ms/step - loss: 1.1999 - accuracy: 0.6107 - val_loss: 3.2195 - val_accuracy: 0.6189\n",
            "Epoch 234/250\n",
            "39/39 [==============================] - 1s 35ms/step - loss: 1.1485 - accuracy: 0.6336 - val_loss: 3.4091 - val_accuracy: 0.6059\n",
            "Epoch 235/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1137 - accuracy: 0.6319 - val_loss: 3.4257 - val_accuracy: 0.6221\n",
            "Epoch 236/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1040 - accuracy: 0.6368 - val_loss: 3.4185 - val_accuracy: 0.6026\n",
            "Epoch 237/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1778 - accuracy: 0.6140 - val_loss: 3.2650 - val_accuracy: 0.6254\n",
            "Epoch 238/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1025 - accuracy: 0.6352 - val_loss: 3.0832 - val_accuracy: 0.6352\n",
            "Epoch 239/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1069 - accuracy: 0.6425 - val_loss: 3.1036 - val_accuracy: 0.6417\n",
            "Epoch 240/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.0518 - accuracy: 0.6490 - val_loss: 3.1181 - val_accuracy: 0.6156\n",
            "Epoch 241/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.0619 - accuracy: 0.6433 - val_loss: 3.2370 - val_accuracy: 0.6189\n",
            "Epoch 242/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.0782 - accuracy: 0.6360 - val_loss: 3.1506 - val_accuracy: 0.6091\n",
            "Epoch 243/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1091 - accuracy: 0.6319 - val_loss: 3.2841 - val_accuracy: 0.6254\n",
            "Epoch 244/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.0629 - accuracy: 0.6417 - val_loss: 3.1085 - val_accuracy: 0.6352\n",
            "Epoch 245/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.0774 - accuracy: 0.6425 - val_loss: 3.3249 - val_accuracy: 0.6221\n",
            "Epoch 246/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.0753 - accuracy: 0.6425 - val_loss: 3.2722 - val_accuracy: 0.6482\n",
            "Epoch 247/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.0844 - accuracy: 0.6107 - val_loss: 3.1991 - val_accuracy: 0.6319\n",
            "Epoch 248/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.1436 - accuracy: 0.6360 - val_loss: 3.1262 - val_accuracy: 0.6287\n",
            "Epoch 249/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.0690 - accuracy: 0.6417 - val_loss: 3.0991 - val_accuracy: 0.6156\n",
            "Epoch 250/250\n",
            "39/39 [==============================] - 1s 33ms/step - loss: 1.0716 - accuracy: 0.6580 - val_loss: 3.3235 - val_accuracy: 0.6156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiEPEW5_WeIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "86ddf776-8a4b-4704-ce61-9fe7adbfc0eb"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.legend(['accuracy', 'val_accuracy'])"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff0190d8c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YALc_iDiXloB",
        "colab_type": "text"
      },
      "source": [
        "### Model Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEW5Bh7PZXh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padding_doc(encoded_doc, max_length):\n",
        "  return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"
      ],
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptxl97vbfgZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "intent_map = {}\n",
        "for intent, onehot_intent in zip(data['intent'].values, test_data):\n",
        "  if (intent not in intent_map):\n",
        "    intent_map[intent] = list(onehot_intent).index(1)"
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWGcFKEFYvTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(text):\n",
        "  # Clean the text first\n",
        "  cleaned_text = re.sub(r'[^ a-z A-Z 0-9]', \" \", text)\n",
        "  test_word = word_tokenize(cleaned_text)\n",
        "  test_word = [w.lower() for w in test_word]\n",
        "  test_ls = tokenizer.texts_to_sequences(test_word)\n",
        "\n",
        "  # Check for unknown words\n",
        "  if [] in test_ls:\n",
        "    test_ls = list(filter(None, test_ls))\n",
        "    \n",
        "  test_ls = np.array(test_ls).reshape(1, len(test_ls))\n",
        "  x = padding_doc(test_ls, max_length)\n",
        "  \n",
        "  prediction_result = model.predict(x)\n",
        "  prediction_result = prediction_result[0]\n",
        "\n",
        "  # convert prediction result to intent word\n",
        "  unique_intents = np.array(list(set(data['intent'])))\n",
        "\n",
        "  # sort value by intent ranking\n",
        "  intent_ranking = {}\n",
        "  for each_intent in unique_intents:\n",
        "    intent_ranking[each_intent] = prediction_result[intent_map[each_intent]]\n",
        "\n",
        "  sorted_intent_ranking = sorted(intent_ranking.items(), key=lambda kv: kv[1], reverse=True)\n",
        "\n",
        "  print(\"Intent Ranking:\")\n",
        "  for each_intent in sorted_intent_ranking:\n",
        "    print(each_intent[0] + \"= \" + str(each_intent[1]) + \" confidence\")"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWHeVaXvZZRP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64f7882c-a65b-48f8-e7c0-0e95ec932d06"
      },
      "source": [
        "predict(\"berapa nomor npwp saya\")"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intent Ranking:\n",
            "ask_npwp= 0.999974 confidence\n",
            "ask_absence_attendance_status_policy= 1.8835635e-05 confidence\n",
            "ask_bpjs_membership= 6.9913053e-06 confidence\n",
            "ask_holiday= 1.1581014e-07 confidence\n",
            "ask_identity_card= 2.0955901e-10 confidence\n",
            "ask_subordinate= 2.6900353e-11 confidence\n",
            "ask_company= 2.2417858e-11 confidence\n",
            "ask_location= 6.2787763e-13 confidence\n",
            "approval_status= 3.8045877e-14 confidence\n",
            "ask_shift= 1.3207748e-14 confidence\n",
            "ask_allowance= 9.716985e-18 confidence\n",
            "approval= 7.6578763e-19 confidence\n",
            "ask_personal_detail= 7.5749856e-19 confidence\n",
            "leave_cancellation_ask_approval_status= 8.993553e-21 confidence\n",
            "absence= 1.2729709e-21 confidence\n",
            "help= 5.9794874e-22 confidence\n",
            "leave_entry_ask_dates= 2.6074233e-24 confidence\n",
            "ask_ump= 2.429876e-24 confidence\n",
            "ask_bpjs_treatment_class= 1.4075977e-24 confidence\n",
            "ask_employment_detail= 3.1239153e-25 confidence\n",
            "register_user_ask_tenant= 5.509286e-26 confidence\n",
            "approval_ask_parameter= 1.8159443e-27 confidence\n",
            "ask_additional_income_prerequisite_after_terminated= 1.38213e-27 confidence\n",
            "ask_additional_income_prerequisite= 1.2101966e-27 confidence\n",
            "absence_cancellation= 2.4843832e-28 confidence\n",
            "ask_allowance_select_type= 7.203594e-29 confidence\n",
            "ask_retirement_age= 2.1599759e-29 confidence\n",
            "balance= 1.1967078e-29 confidence\n",
            "ask_exceed_leave_balance_status= 4.9717505e-30 confidence\n",
            "snooze_notification= 1.497444e-30 confidence\n",
            "ask_bpjs_additional_family= 5.975239e-32 confidence\n",
            "ask_supervisor= 5.9539615e-33 confidence\n",
            "overtime_cancellation_ask_parameter= 8.46212e-34 confidence\n",
            "absence_cancellation_ask_parameter= 3.069691e-34 confidence\n",
            "reimburse_ask_reimbursement_item_number= 2.775775e-34 confidence\n",
            "leave_cancellation_ask_number= 8.882029e-36 confidence\n",
            "absence_ask_parameter= 2.686617e-36 confidence\n",
            "ask_attendance_formula= 2.6523404e-36 confidence\n",
            "ask_family_card_number= 0.0 confidence\n",
            "approve_overtime_notification_ask_paid= 0.0 confidence\n",
            "extend_leave= 0.0 confidence\n",
            "revoke_user_ask_confirmation= 0.0 confidence\n",
            "overtime= 0.0 confidence\n",
            "register_user= 0.0 confidence\n",
            "cancel= 0.0 confidence\n",
            "overtime_ask_confirmation= 0.0 confidence\n",
            "overtime_approval_ask_paid= 0.0 confidence\n",
            "register_user_resend_verification_code= 0.0 confidence\n",
            "absence_cancellation_ask_confirmation= 0.0 confidence\n",
            "leave_entry= 0.0 confidence\n",
            "approve_overtime_notification_ask_template_number= 0.0 confidence\n",
            "leave_cancellation_ask_confirmation= 0.0 confidence\n",
            "disable_push_notification_ask_type= 0.0 confidence\n",
            "overtime_approval_ask_confirmation= 0.0 confidence\n",
            "reimbursement_approval_ask_confirmation= 0.0 confidence\n",
            "absence_ask_confirmation= 0.0 confidence\n",
            "register_user_ask_verification_code= 0.0 confidence\n",
            "ask_payroll_cutoff_date_select_type= 0.0 confidence\n",
            "reimbursement_approval_ask_balance= 0.0 confidence\n",
            "approval_status_ask_status= 0.0 confidence\n",
            "download_payslip= 0.0 confidence\n",
            "approval_ask_confirmation= 0.0 confidence\n",
            "approve_overtime_notification_ask_confirmation= 0.0 confidence\n",
            "revoke_user= 0.0 confidence\n",
            "overtime_approval_ask_template_number= 0.0 confidence\n",
            "balance_next= 0.0 confidence\n",
            "overtime_approval_ask_parameter= 0.0 confidence\n",
            "reject_notification_ask_reason= 0.0 confidence\n",
            "default_fallback_intent= 0.0 confidence\n",
            "overtime_ask_date= 0.0 confidence\n",
            "disable_push_notification= 0.0 confidence\n",
            "leave_entry_ask_leave_type= 0.0 confidence\n",
            "enable_push_notification= 0.0 confidence\n",
            "approve_reimbursement_claim_notification_ask_amount= 0.0 confidence\n",
            "reimbursement_approval_ask_parameter= 0.0 confidence\n",
            "reimburse= 0.0 confidence\n",
            "reimburse_ask_family_member= 0.0 confidence\n",
            "overtime_ask_start_time= 0.0 confidence\n",
            "ask_dental_facility= 0.0 confidence\n",
            "thank_you= 0.0 confidence\n",
            "ask_lateness_deduct_overtime= 0.0 confidence\n",
            "approve_reimbursement_claim_notification_ask_confirmation= 0.0 confidence\n",
            "leave_cancellation_approved_ask_date= 0.0 confidence\n",
            "ask_overtime_calculation_method= 0.0 confidence\n",
            "ask_payroll_cutoff_date= 0.0 confidence\n",
            "leave_balance_detail= 0.0 confidence\n",
            "overtime_cancellation= 0.0 confidence\n",
            "overtime_cancellation_ask_confirmation= 0.0 confidence\n",
            "absence_ask_absence_status_number= 0.0 confidence\n",
            "ask_catapa= 0.0 confidence\n",
            "balance_previous= 0.0 confidence\n",
            "enable_push_notification_ask_type= 0.0 confidence\n",
            "ask_claudia= 0.0 confidence\n",
            "reject_notification_ask_confirmation= 0.0 confidence\n",
            "reimburse_ask_confirmation= 0.0 confidence\n",
            "ask_healthcare_facility= 0.0 confidence\n",
            "offer_help= 0.0 confidence\n",
            "leave_cancellation= 0.0 confidence\n",
            "see_approval_detail_notification_ask_approve_reject= 0.0 confidence\n",
            "leave_entry_ask_confirmation= 0.0 confidence\n",
            "reimburse_ask_claimed_amount= 0.0 confidence\n",
            "approve_notification_ask_confirmation= 0.0 confidence\n",
            "leave_entry_half_day_ask_start_time= 0.0 confidence\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7lRBeJYu-X8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}