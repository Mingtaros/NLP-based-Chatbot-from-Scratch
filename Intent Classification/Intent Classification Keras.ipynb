{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq9_ekc_QASY"
   },
   "source": [
    "# Intent Classification using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7TFYlPSRMgw",
    "outputId": "7344fa2a-220e-437d-ecc0-f848b36c44fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Leonardo\n",
      "[nltk_data]     W\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Or2ggueYLUuU"
   },
   "outputs": [],
   "source": [
    "# Data Processing - Main\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Data Processing - Tokenizer and Encoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk import word_tokenize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Data Processing - Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Bidirectional, LSTM, Dropout\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "\n",
    "# Misc.\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oy-lflMILcGK",
    "outputId": "e5c0eadb-4073-4cdd-d632-f708aa1451c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test gpu availability\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_9DysW7IB6R",
    "outputId": "092bf7e6-e5dc-436c-b236-49f7a09f8b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 02 18:51:21 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 452.06       Driver Version: 452.06       CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 166... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   44C    P8     7W /  N/A |    153MiB /  6144MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      8292    C+G   ...an\\app-7.34.0\\Postman.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mvT6mybCMSrR"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 13517048\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1MYop3XQGcX"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "NkMo3bXBMziv",
    "outputId": "65d1342d-6b00-4231-aafd-42f0b8221ad4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mau absen 11-14 februari 2020</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mau absen 11 - 14 februari 2020</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sick leave besok</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aku mau absence besok</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>change working hours besok</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>change working hour besok</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>absen besok</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>change working hours</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sick leave</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mau absen tanggal 10-11 januari 2012</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text   intent\n",
       "0         mau absen 11-14 februari 2020  absence\n",
       "1       mau absen 11 - 14 februari 2020  absence\n",
       "2                      sick leave besok  absence\n",
       "3                 aku mau absence besok  absence\n",
       "4            change working hours besok  absence\n",
       "5             change working hour besok  absence\n",
       "6                           absen besok  absence\n",
       "7                  change working hours  absence\n",
       "8                            sick leave  absence\n",
       "9  mau absen tanggal 10-11 januari 2012  absence"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"nlu.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBdUkbOwH6nJ",
    "outputId": "9286c5a7-9f62-4844-a4a7-dd6160921fe3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "approval_status                           80\n",
       "approval                                  57\n",
       "leave_entry                               54\n",
       "approval_ask_parameter                    52\n",
       "absence                                   46\n",
       "                                          ..\n",
       "approval_ask_confirmation                  2\n",
       "reject_notification_ask_reason             2\n",
       "approve_overtime_notification_ask_paid     2\n",
       "leave_entry_half_day_ask_start_time        1\n",
       "default_fallback_intent                    1\n",
       "Name: intent, Length: 103, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOBrw6JjGIrn"
   },
   "source": [
    "### USE ONLY SOME DATA INTENTS\n",
    "\n",
    "<b>Intents to use:</b>\n",
    "- absence\n",
    "- thankyou\n",
    "- cancel\n",
    "- help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "x8FuqlklGm01",
    "outputId": "f62a2802-247c-4293-8f65-ac830a90a38f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mau absen 11-14 februari 2020</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mau absen 11 - 14 februari 2020</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sick leave besok</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aku mau absence besok</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>change working hours besok</td>\n",
       "      <td>absence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text   intent\n",
       "0    mau absen 11-14 februari 2020  absence\n",
       "1  mau absen 11 - 14 februari 2020  absence\n",
       "2                 sick leave besok  absence\n",
       "3            aku mau absence besok  absence\n",
       "4       change working hours besok  absence"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['intent'].isin(['absence', 'thank_you', 'cancel', 'help', 'default_fallback_intent'])]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8uJ4z3uIH01o",
    "outputId": "335d912b-41bd-44e5-9aa0-56d93f6f76a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absence                    46\n",
       "cancel                     33\n",
       "thank_you                  22\n",
       "help                       20\n",
       "default_fallback_intent     1\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4b23jlRLNF_j"
   },
   "outputs": [],
   "source": [
    "# Clean data:\n",
    "#   - Strip data from special characters\n",
    "#   - Tokenize words\n",
    "#   - Lowercase all word\n",
    "def clean_data(text_data):\n",
    "  words = []\n",
    "  for sentence in text_data:\n",
    "    clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", sentence)\n",
    "    tokenized_words = word_tokenize(clean)\n",
    "\n",
    "    words.append([word.lower() for word in tokenized_words])\n",
    "\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UoEFDLchPDrS"
   },
   "outputs": [],
   "source": [
    "# Get max length of every word in words\n",
    "def get_max_length(words):\n",
    "  return len(max(words, key = len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "i6KvNcrcPH6S"
   },
   "outputs": [],
   "source": [
    "filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'\n",
    "\n",
    "def create_tokenizer(words):\n",
    "  token = Tokenizer(filters = filters)\n",
    "  token.fit_on_texts(words)\n",
    "  return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7m8b5hHwP-3K"
   },
   "outputs": [],
   "source": [
    "def create_train_data(text_data):\n",
    "  # Encoding document\n",
    "  token = create_tokenizer(text_data)\n",
    "  sequences = token.texts_to_sequences(text_data)\n",
    "\n",
    "  max_length = get_max_length(sequences)\n",
    "  return pad_sequences(sequences, maxlen=max_length, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Gice1iwHRhfD"
   },
   "outputs": [],
   "source": [
    "def onehot_encode(data):\n",
    "  encoder = OneHotEncoder(sparse=False)\n",
    "  return encoder.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Rl2lvxuDXOL7"
   },
   "outputs": [],
   "source": [
    "cleaned_data = clean_data(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UFj_E_-qXNWW"
   },
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer(cleaned_data)\n",
    "MAX_LENGTH = get_max_length(cleaned_data)\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "D23pwDQgSWla"
   },
   "outputs": [],
   "source": [
    "train_data = create_train_data(cleaned_data)\n",
    "test_data = onehot_encode(data['intent'].values.reshape(-1, 1))\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_data, test_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOJUTX77S_WG"
   },
   "source": [
    "## Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "C6FtIWWETo5N"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(VOCAB_SIZE, 512, input_length=MAX_LENGTH, trainable=False))\n",
    "model.add(Bidirectional(LSTM(512)))\n",
    "\n",
    "model.add(Dense(64, activation = \"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32, activation = \"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(y_train.shape[1], activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lN_VqsMkVfL3",
    "outputId": "a0764b58-49ec-4c37-fc1e-226c4e15395a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 10, 512)           61440     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1024)              4198400   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 4,327,685\n",
      "Trainable params: 4,266,245\n",
      "Non-trainable params: 61,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZP5ElhpNYq4x"
   },
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "G3lsazb9Yb6J"
   },
   "outputs": [],
   "source": [
    "# Fit constants\n",
    "\n",
    "EPOCHS = [100, 10]\n",
    "BASIZE = [32, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "crepStCMWAI5",
    "outputId": "c22349c2-2dd6-4f0d-c810-91333b14b3c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "for ep, bs in zip(EPOCHS, BASIZE):\n",
    "  history = model.fit(x_train, y_train, epochs=ep, batch_size=bs, validation_data=(x_val, y_val))\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "  plt.legend(['accuracy', 'val_accuracy'])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YALc_iDiXloB"
   },
   "source": [
    "### Model Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "bEW5Bh7PZXh7"
   },
   "outputs": [],
   "source": [
    "def padding_doc(encoded_doc, max_length):\n",
    "  return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Ptxl97vbfgZv"
   },
   "outputs": [],
   "source": [
    "intent_map = {}\n",
    "for intent, onehot_intent in zip(data['intent'].values, test_data):\n",
    "  if (intent not in intent_map):\n",
    "    intent_map[intent] = list(onehot_intent).index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k32WowcDaU_6",
    "outputId": "6c10d252-46fd-454d-da61-8aab61209d48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'absence': 0,\n",
       " 'cancel': 1,\n",
       " 'help': 3,\n",
       " 'default_fallback_intent': 2,\n",
       " 'thank_you': 4}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EWGcFKEFYvTC"
   },
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "  # Clean the text first\n",
    "  cleaned_text = re.sub(r'[^ a-z A-Z 0-9]', \" \", text)\n",
    "  test_word = word_tokenize(cleaned_text)\n",
    "  test_word = [w.lower() for w in test_word]\n",
    "  test_ls = tokenizer.texts_to_sequences(test_word)\n",
    "\n",
    "  # Check for unknown words\n",
    "  if [] in test_ls:\n",
    "    test_ls = list(filter(None, test_ls))\n",
    "    \n",
    "  test_ls = np.array(test_ls).reshape(1, len(test_ls))\n",
    "  x = padding_doc(test_ls, MAX_LENGTH)\n",
    "  prediction_result = model.predict(x)\n",
    "  prediction_result = prediction_result[0]\n",
    "\n",
    "  # convert prediction result to intent word\n",
    "  unique_intents = intent_map.keys()\n",
    "\n",
    "  # sort value by intent ranking\n",
    "  intent_ranking = {}\n",
    "  for each_intent in unique_intents:\n",
    "    intent_ranking[each_intent] = prediction_result[intent_map[each_intent]]\n",
    "\n",
    "  sorted_intent_ranking = sorted(intent_ranking.items(), key=lambda kv: kv[1], reverse=True)\n",
    "  print(dict(sorted_intent_ranking))\n",
    "  print(\"Intent Ranking:\")\n",
    "  for each_intent in sorted_intent_ranking:\n",
    "    print(each_intent[0] + \"= \" + str(each_intent[1]) + \" confidence\")\n",
    "\n",
    "  return sorted_intent_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWHeVaXvZZRP",
    "outputId": "0bbf0cad-8eca-4100-8915-f9ed36892fd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cancel': 0.9450395, 'absence': 0.054714642, 'thank_you': 0.00015589596, 'help': 8.0344544e-05, 'default_fallback_intent': 9.680959e-06}\n",
      "Intent Ranking:\n",
      "cancel= 0.9450395 confidence\n",
      "absence= 0.054714642 confidence\n",
      "thank_you= 0.00015589596 confidence\n",
      "help= 8.0344544e-05 confidence\n",
      "default_fallback_intent= 9.680959e-06 confidence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cancel', 0.9450395),\n",
       " ('absence', 0.054714642),\n",
       " ('thank_you', 0.00015589596),\n",
       " ('help', 8.0344544e-05),\n",
       " ('default_fallback_intent', 9.680959e-06)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"gajadi deh, mau makan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7lRBeJYu-X8"
   },
   "source": [
    "## Save ML Model\n",
    "\n",
    "To be called in django intent app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9lNPNY8J-Dt",
    "outputId": "6b0325a8-1dc8-4de1-faf5-ea9f0504517e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\leonardo w\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From c:\\users\\leonardo w\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_model/intent_model_best\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"saved_model/intent_model_best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYSvQ697l3iV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Intent Classification Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
