{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9PKgvGUAyTw",
    "outputId": "e6bb9cd1-5509-438b-fda7-08c7ac049d16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Leonardo\n",
      "[nltk_data]     W\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, Embedding, TimeDistributed, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s66NZbODBJ09"
   },
   "outputs": [],
   "source": [
    "def replace_with_entity(re_group):\n",
    "    # replace every ENAMEX tag in sentence with the entity itself\n",
    "    entity = re.findall(r'<ENAMEX TYPE=.*?>(.*?)</ENAMEX>', re_group)\n",
    "    return entity[0]\n",
    "\n",
    "\n",
    "def find_index_in_sentence(patterns, sentence):\n",
    "    # find index of start and end of occured entity in sentence\n",
    "    index_in_sentence = []\n",
    "    for pattern in patterns:\n",
    "        # add regex special characters in pattern with backslash\n",
    "        pattern = re.sub('\\(', '\\\\(', pattern)\n",
    "        pattern = re.sub('\\)', '\\\\)', pattern)\n",
    "        pattern = re.sub('\\+', '\\\\+', pattern)\n",
    "        pattern = re.sub('\\$', '\\\\$', pattern)\n",
    "\n",
    "        index_in_sentence.append([(index.start(0), index.end(0)) for index in re.finditer(pattern, sentence)][0])\n",
    "\n",
    "    return index_in_sentence\n",
    "\n",
    "\n",
    "def read_enamex_file(filename):\n",
    "    # open file with enamex XML Entities\n",
    "    # convert it to standard SpaCy training dataset for NER\n",
    "    with open(filename, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # remove \\t...\\n from the content data\n",
    "    content_removed_endline = re.sub('\\t.*?\\n', '', content)\n",
    "\n",
    "    # split the content to list of sentences\n",
    "    before_sentences = content_removed_endline.split(\".\")\n",
    "    train_data = []\n",
    "\n",
    "    # converted the splitted content to list of tuple\n",
    "    # showing where the entity occur and what's the entity\n",
    "    for each_sentence in before_sentences:\n",
    "        if each_sentence == \"\":\n",
    "            continue\n",
    "        # find enamex for every sentence\n",
    "        entities = re.findall(r'<ENAMEX TYPE=.*?>(.*?)</ENAMEX>', each_sentence)\n",
    "        types = re.findall(r'<ENAMEX TYPE=\\\"(.*?)\\\">.*?</ENAMEX>', each_sentence)\n",
    "\n",
    "        # replace XML ENAMEX with entity\n",
    "        new_sentence = re.sub(r'<ENAMEX TYPE=.*?>.*?</ENAMEX>', lambda enamex: replace_with_entity(enamex.group()), each_sentence)\n",
    "\n",
    "        index_in_sentence = find_index_in_sentence(entities, new_sentence)\n",
    "\n",
    "        #append to train data with format = (new_sentence, {\"entities\": [(start, end, type)]})\n",
    "        entity_dictionary = {\n",
    "            \"entities\": []\n",
    "        }\n",
    "\n",
    "        for entity_type, entity_index in zip(types, index_in_sentence):\n",
    "            # only append if entities don't overlap\n",
    "            check_overlap = False\n",
    "            for entity in entity_dictionary[\"entities\"]:\n",
    "                if ((entity_index[0] >= entity[0] and entity_index[0] <= entity[1]) or (entity_index[1] <= entity[1] and entity_index[1] >= entity[0])):\n",
    "                    check_overlap = True\n",
    "\n",
    "            if (not check_overlap and entity_type == 'DATETIME'): # ONLY TAKE DATETIME DATA\n",
    "                entity_dictionary[\"entities\"].append((entity_index[0], entity_index[1], entity_type))\n",
    "        train_data.append((new_sentence, entity_dictionary))\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jJwZL5-hBPLP"
   },
   "outputs": [],
   "source": [
    "data_read = read_enamex_file('ner_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "a68r8JzeBT2w"
   },
   "outputs": [],
   "source": [
    "def preprocessData(sentence):\n",
    "  result = ' '.join(sentence.lower().split('-'))\n",
    "  result = nltk.word_tokenize(result)\n",
    "  return result\n",
    "\n",
    "def changeDataFormat(data_read):\n",
    "  x_data = []\n",
    "  y_data = []\n",
    "  # Label 0 = other, 1 = date\n",
    "  for data in data_read:\n",
    "    words = preprocessData(data[0])\n",
    "    label = [0 for i in range(len(words))]\n",
    "    for entities in data[1]['entities']:\n",
    "\n",
    "      ner_words = data[0][entities[0]:entities[1]]\n",
    "      ner_words = preprocessData(ner_words)\n",
    "\n",
    "      ner_count = 0\n",
    "      idx_word = 0\n",
    "      while (ner_count < len(ner_words) and idx_word < len(words)):\n",
    "        if words[idx_word] == ner_words[ner_count]:\n",
    "          label[idx_word] = 1\n",
    "          ner_count += 1\n",
    "        idx_word += 1\n",
    "    x_data.append(words)\n",
    "    y_data.append(label)\n",
    "  return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "1XhvcRTlsLr8",
    "outputId": "7e8f94f4-ae96-4a2a-a0ff-bb6c4e2bcdcb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = changeDataFormat(data_read)\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "plt.hist([len(s) for s in x], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Q010eURNuRTV"
   },
   "outputs": [],
   "source": [
    "def encodeXData(x):\n",
    "  new_x = []\n",
    "  for sentence in x:\n",
    "    new_seq = []\n",
    "    for word in sentence:\n",
    "      try:\n",
    "        new_seq.append(word2index[word.lower()])\n",
    "      except KeyError:\n",
    "        new_seq.append(word2index['OOVword'])\n",
    "    new_x.append(new_seq)\n",
    "  return new_x\n",
    "\n",
    "\n",
    "def dataToMaxLength(x, y, max_len):\n",
    "  new_x = pad_sequences(maxlen=max_len, sequences=x, padding=\"post\", value=0)\n",
    "  new_y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=0)\n",
    "  return np.array(new_x), np.array(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UYwlKS5jzXgN"
   },
   "outputs": [],
   "source": [
    "words = set([])\n",
    "for sentence in x:\n",
    "  for word in sentence:\n",
    "    words.add(word.lower())\n",
    "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
    "word2index['PADword'] = 0\n",
    "word2index['OOVword'] = 1\n",
    "encoded_x = encodeXData(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "79D8LTx1-xWE"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "fixed_x = pad_sequences(maxlen=MAX_LEN, sequences=encoded_x, padding=\"post\", value=0)\n",
    "fixed_y = pad_sequences(maxlen=MAX_LEN, sequences=y, padding=\"post\", value=0)\n",
    "x_train = fixed_x\n",
    "y_train = fixed_y\n",
    "# x_train, x_test, y_train, y_test = train_test_split(fixed_x, fixed_y, test_size=0.1, random_state=13517054)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LLTPYnYU3LsS"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LEN, )))\n",
    "model.add(Embedding(len(word2index), 64))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uvHm461Y5gQq",
    "outputId": "b99b1d94-0ba0-4d8d-dd61-f357faae646a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 64)            482368    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 50, 64)            24832     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 50, 1)             65        \n",
      "=================================================================\n",
      "Total params: 507,265\n",
      "Trainable params: 507,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-BzW45E5-7Z",
    "outputId": "76d0b61c-5885-4961-8975-05ae9d0d4492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 0.1998 - accuracy: 0.9914 - val_loss: 0.1021 - val_accuracy: 0.9777\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 0.0352 - accuracy: 0.9945 - val_loss: 0.0921 - val_accuracy: 0.9777\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0280 - accuracy: 0.9945 - val_loss: 0.0799 - val_accuracy: 0.9777\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.0696 - val_accuracy: 0.9777\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0118 - accuracy: 0.9952 - val_loss: 0.0569 - val_accuracy: 0.9793\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.0486 - val_accuracy: 0.9813\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0436 - val_accuracy: 0.9834\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0400 - val_accuracy: 0.9844\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0384 - val_accuracy: 0.9850\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0368 - val_accuracy: 0.9856\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0363 - val_accuracy: 0.9875\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0375 - val_accuracy: 0.9880\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0358 - val_accuracy: 0.9885\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0362 - val_accuracy: 0.9885\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 9.2966e-04 - accuracy: 0.9999 - val_loss: 0.0366 - val_accuracy: 0.9893\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 8.2162e-04 - accuracy: 0.9999 - val_loss: 0.0378 - val_accuracy: 0.9889\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 7.4747e-04 - accuracy: 0.9999 - val_loss: 0.0372 - val_accuracy: 0.9894\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 6.6758e-04 - accuracy: 0.9999 - val_loss: 0.0385 - val_accuracy: 0.9894\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 5.9277e-04 - accuracy: 0.9999 - val_loss: 0.0382 - val_accuracy: 0.9896\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 6.8689e-04 - accuracy: 0.9999 - val_loss: 0.0418 - val_accuracy: 0.9889\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=32, validation_split=0.1, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rgELBNWa6Jt4"
   },
   "outputs": [],
   "source": [
    "def getIndex(data):\n",
    "  for key in word2index:\n",
    "    if word2index[key] == data:\n",
    "      return key\n",
    "\n",
    "def predict(text):\n",
    "  test_data = preprocessData(text)\n",
    "  test_data = encodeXData([test_data])[0]\n",
    "  pred = model.predict(test_data)\n",
    "  normalized_pred = [1 if a > 0.5 else 0 for a in pred]\n",
    "  labelled_token = []\n",
    "  for i, label in enumerate(normalized_pred):\n",
    "    if label == 1:\n",
    "      labelled_token.append(getIndex(test_data[i]))\n",
    "  return labelled_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYdVK6GbVgiE",
    "outputId": "58cfd9d5-951f-4dea-d5a1-a9e2d1feac06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 50) for input Tensor(\"input_1:0\", shape=(None, 50), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['11', '20', 'januari']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('mau cuti tanggal 11 20 januari hehe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3ILgadYYW_js"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\leonardo w\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From c:\\users\\leonardo w\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_model/ner_model_best\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"saved_model/ner_model_best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NER Tanggal",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
